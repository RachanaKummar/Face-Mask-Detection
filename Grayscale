import cv2
import os
import numpy as np
from keras.models import load_model
from keras.utils import np_utils  #collection of utilities for array and list manipulation
#listing out the folders 
data_path=(r"dataset_path")
categories=os.listdir(data_path) #names of the folders
labels=[i for i in range(0,len(categories))] # no of folders

label_dict=dict(zip(categories,labels)) # dictionary 
print(labels)
print(categories)
print(label_dict)

img_size=100  #fixing the size of the input image to 100
data=[]
target=[]

#reading all the images 
for category in categories:
    folder_path=os.path.join(data_path,category)
    img_names=os.listdir(folder_path)
    #print(img_names)-- list of all the images
    
    for img_name in img_names:
        img_path=os.path.join(folder_path,img_name)
        img=cv2.imread(img_path)
        
        try:
            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #converting the images into grayscale
            resized=cv2.resize(gray,(img_size,img_size))
            data.append(resized)
            target.append(label_dict[category])
            
        except Exception as e:
            print('Invalid image file!\n',e)
            

import numpy as np
from keras.utils import np_utils
data=np.array(data)/255.0  # dividing all the pixels by 255 so that all the pixel values lie between 0 and 1
data=np.reshape(data,(data.shape[0],img_size,img_size,1)) #1-grayscale
target=np.array(target)
new_target=np_utils.to_categorical(target)  # output is categorical data 

np.save('data',data)
np.save('target',new_target)

data=np.load('data.npy')
target=np.load('target.npy')

# CNN 
from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten,Dropout
from keras.layers import Conv2D,MaxPooling2D
from keras.callbacks import ModelCheckpoint # to save the best epoch



model=Sequential()

model.add(Conv2D(300,(3,3),input_shape=data.shape[1:],activation='relu'))
#300- amount of output filter in the convolution. 
#Numbers 3, 3 correspond to the kernel size, which determinate the width and height of the 2D convolution window.
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(200,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(100,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dropout(0.5))  # to avoid overfitting

model.add(Dense(50,activation='relu'))  #output layer
model.add(Dense(2,activation='softmax'))

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

from sklearn.model_selection import train_test_split

train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.2)
#test set is used to evaluate the trained model by using the unseen data by the model.
checkpoint=ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')

history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)
#The validation set uses the tarining data to evaluate a given model, but this is for frequent evaluation.

model.save('name.h5')
print(model.evaluate(test_data,test_target))

model = load_model(name.h5)
#classifier used for detection
face_clsfr=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')
source = cv2.VideoCapture(0)
labels_dict={1:'Mask',0:'No Mask'}
color_dict ={0:(0,255,0),1:(0,0,255)}
while(True):
    ret,img = source.read()
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    faces = face_clsfr.detectMultiScale(gray,1.3,5)
    
    for x,y,w,h in faces:
        face_img = gray[y:y+w,x:x+w]
        resized=cv2.resize(face_img,(100,100))
        normalized=resized/255.0
        reshaped=np.reshape(normalized,(1,100,100,1))
        result=model.predict(reshaped)
        
        label=np.argmax(result,axis=1)[0]
        cv2.rectangle(gray,(x,y),(x+w,y+h),color_dict[label],2)
        cv2.rectangle(gray,(x,y-35),(x+w,y),color_dict[label],-1)
        cv2.putText(gray,labels_dict[label],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)
    
    cv2.imshow('LIVE',gray)
    if cv2.waitKey(20) & 0xFF == ord('q'):
        break
cv2.destroyAllWindows()
source.release()

